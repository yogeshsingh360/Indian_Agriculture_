{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09f1051f-2159-40ed-9844-554849fd5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a64b0c3b-1501-4e84-af98-47f0fd2e600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_after_cleaning.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "885a9aa7-6d43-4e4a-b6d1-dbdffa4dc85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crop']=df['crop'].str.replace(' ','')\n",
    "df['season']=df['season'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7becf324-4f34-46bd-a889-e60768e4c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='crop_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "981ae610-04c6-45c7-8be5-a622449c8c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_year</th>\n",
       "      <th>season</th>\n",
       "      <th>crop</th>\n",
       "      <th>area</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>relative_humidity_2m_mean</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crop_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>banana</td>\n",
       "      <td>7.367077</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>0.256219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coconut</td>\n",
       "      <td>6.747587</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>8.185731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coriander</td>\n",
       "      <td>8.464214</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>0.211902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>drychillies</td>\n",
       "      <td>8.233769</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>1.062281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>13.539363</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>0.364643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249491</th>\n",
       "      <td>2020</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>9.114160</td>\n",
       "      <td>12.551224</td>\n",
       "      <td>2.734038</td>\n",
       "      <td>60.397664</td>\n",
       "      <td>3.186096</td>\n",
       "      <td>30.729860</td>\n",
       "      <td>78.443420</td>\n",
       "      <td>0.983564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249460</th>\n",
       "      <td>2020</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>turmeric</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>12.463553</td>\n",
       "      <td>6.557644</td>\n",
       "      <td>56.127426</td>\n",
       "      <td>3.479982</td>\n",
       "      <td>30.608720</td>\n",
       "      <td>79.065170</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249485</th>\n",
       "      <td>2020</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>9.965476</td>\n",
       "      <td>7.998832</td>\n",
       "      <td>2.927197</td>\n",
       "      <td>71.856507</td>\n",
       "      <td>5.530812</td>\n",
       "      <td>29.390529</td>\n",
       "      <td>79.460869</td>\n",
       "      <td>1.573525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249431</th>\n",
       "      <td>2020</td>\n",
       "      <td>kharif</td>\n",
       "      <td>soyabean</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>19.961075</td>\n",
       "      <td>13.932401</td>\n",
       "      <td>85.659140</td>\n",
       "      <td>3.244839</td>\n",
       "      <td>30.008790</td>\n",
       "      <td>79.928018</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249468</th>\n",
       "      <td>2020</td>\n",
       "      <td>summer</td>\n",
       "      <td>urad</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>23.703710</td>\n",
       "      <td>1.304355</td>\n",
       "      <td>55.102151</td>\n",
       "      <td>5.963441</td>\n",
       "      <td>30.325565</td>\n",
       "      <td>78.043681</td>\n",
       "      <td>0.798508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249492 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crop_year     season         crop       area  ...  wind_speed_10m_mean   latitude  longitude  crop_yield\n",
       "29           2001  wholeyear       banana   7.367077  ...            13.118321  14.724220  77.430674    0.256219\n",
       "30           2001  wholeyear      coconut   6.747587  ...            13.118321  14.724220  77.430674    8.185731\n",
       "31           2001  wholeyear    coriander   8.464214  ...            13.118321  14.724220  77.430674    0.211902\n",
       "4            2001     kharif  drychillies   8.233769  ...            21.165090  14.724220  77.430674    1.062281\n",
       "5            2001     kharif    groundnut  13.539363  ...            21.165090  14.724220  77.430674    0.364643\n",
       "...           ...        ...          ...        ...  ...                  ...        ...        ...         ...\n",
       "249491       2020       rabi        wheat   9.114160  ...             3.186096  30.729860  78.443420    0.983564\n",
       "249460       2020  wholeyear     turmeric   0.693147  ...             3.479982  30.608720  79.065170    1.098612\n",
       "249485       2020       rabi        wheat   9.965476  ...             5.530812  29.390529  79.460869    1.573525\n",
       "249431       2020     kharif     soyabean   3.610918  ...             3.244839  30.008790  79.928018    0.693147\n",
       "249468       2020     summer         urad   2.302585  ...             5.963441  30.325565  78.043681    0.798508\n",
       "\n",
       "[249492 rows x 11 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ab1a105-ba09-4acd-ba5a-06d4446e4603",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['crop_year'] <= 2017]\n",
    "test_df = df[df['crop_year'] > 2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d12d444-928c-428d-bbc3-7590ceac7795",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(columns=['crop_yield'])\n",
    "y_train = train_df['crop_yield']\n",
    "\n",
    "x_test = test_df.drop(columns=['crop_yield'])\n",
    "y_test = test_df['crop_yield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7265c2f5-c7d3-4dbe-b34d-5f2da688d072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_year</th>\n",
       "      <th>season</th>\n",
       "      <th>crop</th>\n",
       "      <th>area</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>relative_humidity_2m_mean</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>banana</td>\n",
       "      <td>7.367077</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coconut</td>\n",
       "      <td>6.747587</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coriander</td>\n",
       "      <td>8.464214</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>drychillies</td>\n",
       "      <td>8.233769</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>13.539363</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230935</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>24.916359</td>\n",
       "      <td>1.022696</td>\n",
       "      <td>72.918779</td>\n",
       "      <td>9.358756</td>\n",
       "      <td>22.064845</td>\n",
       "      <td>87.837759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230936</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>5.198497</td>\n",
       "      <td>25.175461</td>\n",
       "      <td>0.705012</td>\n",
       "      <td>61.695276</td>\n",
       "      <td>8.248041</td>\n",
       "      <td>22.420000</td>\n",
       "      <td>87.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230937</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>23.105588</td>\n",
       "      <td>0.319528</td>\n",
       "      <td>65.649194</td>\n",
       "      <td>7.725115</td>\n",
       "      <td>24.174599</td>\n",
       "      <td>88.272133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230938</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>8.136811</td>\n",
       "      <td>24.080357</td>\n",
       "      <td>0.675058</td>\n",
       "      <td>60.582373</td>\n",
       "      <td>7.733410</td>\n",
       "      <td>23.388409</td>\n",
       "      <td>87.960676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230939</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>6.959399</td>\n",
       "      <td>24.102247</td>\n",
       "      <td>0.149251</td>\n",
       "      <td>46.248272</td>\n",
       "      <td>7.849136</td>\n",
       "      <td>23.202097</td>\n",
       "      <td>86.322899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213518 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crop_year     season         crop  ...  wind_speed_10m_mean   latitude  longitude\n",
       "29           2001  wholeyear       banana  ...            13.118321  14.724220  77.430674\n",
       "30           2001  wholeyear      coconut  ...            13.118321  14.724220  77.430674\n",
       "31           2001  wholeyear    coriander  ...            13.118321  14.724220  77.430674\n",
       "4            2001     kharif  drychillies  ...            21.165090  14.724220  77.430674\n",
       "5            2001     kharif    groundnut  ...            21.165090  14.724220  77.430674\n",
       "...           ...        ...          ...  ...                  ...        ...        ...\n",
       "230935       2017       rabi        wheat  ...             9.358756  22.064845  87.837759\n",
       "230936       2017       rabi        wheat  ...             8.248041  22.420000  87.320000\n",
       "230937       2017       rabi        wheat  ...             7.725115  24.174599  88.272133\n",
       "230938       2017       rabi        wheat  ...             7.733410  23.388409  87.960676\n",
       "230939       2017       rabi        wheat  ...             7.849136  23.202097  86.322899\n",
       "\n",
       "[213518 rows x 10 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8045fa39-abce-4abf-b0ef-1eca7ae22487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_year</th>\n",
       "      <th>season</th>\n",
       "      <th>crop</th>\n",
       "      <th>area</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>relative_humidity_2m_mean</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196293</th>\n",
       "      <td>2018</td>\n",
       "      <td>kharif</td>\n",
       "      <td>arhar/tur</td>\n",
       "      <td>8.337827</td>\n",
       "      <td>30.524337</td>\n",
       "      <td>1.639104</td>\n",
       "      <td>57.123297</td>\n",
       "      <td>18.537061</td>\n",
       "      <td>14.475294</td>\n",
       "      <td>78.821686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196292</th>\n",
       "      <td>2018</td>\n",
       "      <td>rabi</td>\n",
       "      <td>arhar/tur</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>27.324539</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>65.982719</td>\n",
       "      <td>9.026267</td>\n",
       "      <td>16.291519</td>\n",
       "      <td>80.454159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196323</th>\n",
       "      <td>2018</td>\n",
       "      <td>kharif</td>\n",
       "      <td>bajra</td>\n",
       "      <td>4.418841</td>\n",
       "      <td>28.712652</td>\n",
       "      <td>8.850824</td>\n",
       "      <td>77.973477</td>\n",
       "      <td>9.236416</td>\n",
       "      <td>18.114126</td>\n",
       "      <td>83.411439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196322</th>\n",
       "      <td>2018</td>\n",
       "      <td>kharif</td>\n",
       "      <td>bajra</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>28.544194</td>\n",
       "      <td>9.827921</td>\n",
       "      <td>81.937993</td>\n",
       "      <td>11.404050</td>\n",
       "      <td>18.294931</td>\n",
       "      <td>83.893884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196321</th>\n",
       "      <td>2018</td>\n",
       "      <td>rabi</td>\n",
       "      <td>bajra</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>26.882892</td>\n",
       "      <td>0.226152</td>\n",
       "      <td>66.549539</td>\n",
       "      <td>9.343433</td>\n",
       "      <td>14.717439</td>\n",
       "      <td>79.660506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249491</th>\n",
       "      <td>2020</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>9.114160</td>\n",
       "      <td>12.551224</td>\n",
       "      <td>2.734038</td>\n",
       "      <td>60.397664</td>\n",
       "      <td>3.186096</td>\n",
       "      <td>30.729860</td>\n",
       "      <td>78.443420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249460</th>\n",
       "      <td>2020</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>turmeric</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>12.463553</td>\n",
       "      <td>6.557644</td>\n",
       "      <td>56.127426</td>\n",
       "      <td>3.479982</td>\n",
       "      <td>30.608720</td>\n",
       "      <td>79.065170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249485</th>\n",
       "      <td>2020</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>9.965476</td>\n",
       "      <td>7.998832</td>\n",
       "      <td>2.927197</td>\n",
       "      <td>71.856507</td>\n",
       "      <td>5.530812</td>\n",
       "      <td>29.390529</td>\n",
       "      <td>79.460869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249431</th>\n",
       "      <td>2020</td>\n",
       "      <td>kharif</td>\n",
       "      <td>soyabean</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>19.961075</td>\n",
       "      <td>13.932401</td>\n",
       "      <td>85.659140</td>\n",
       "      <td>3.244839</td>\n",
       "      <td>30.008790</td>\n",
       "      <td>79.928018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249468</th>\n",
       "      <td>2020</td>\n",
       "      <td>summer</td>\n",
       "      <td>urad</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>23.703710</td>\n",
       "      <td>1.304355</td>\n",
       "      <td>55.102151</td>\n",
       "      <td>5.963441</td>\n",
       "      <td>30.325565</td>\n",
       "      <td>78.043681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35974 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crop_year     season       crop      area  ...  relative_humidity_2m_mean  wind_speed_10m_mean   latitude  longitude\n",
       "196293       2018     kharif  arhar/tur  8.337827  ...                  57.123297            18.537061  14.475294  78.821686\n",
       "196292       2018       rabi  arhar/tur  6.966967  ...                  65.982719             9.026267  16.291519  80.454159\n",
       "196323       2018     kharif      bajra  4.418841  ...                  77.973477             9.236416  18.114126  83.411439\n",
       "196322       2018     kharif      bajra  4.442651  ...                  81.937993            11.404050  18.294931  83.893884\n",
       "196321       2018       rabi      bajra  0.693147  ...                  66.549539             9.343433  14.717439  79.660506\n",
       "...           ...        ...        ...       ...  ...                        ...                  ...        ...        ...\n",
       "249491       2020       rabi      wheat  9.114160  ...                  60.397664             3.186096  30.729860  78.443420\n",
       "249460       2020  wholeyear   turmeric  0.693147  ...                  56.127426             3.479982  30.608720  79.065170\n",
       "249485       2020       rabi      wheat  9.965476  ...                  71.856507             5.530812  29.390529  79.460869\n",
       "249431       2020     kharif   soyabean  3.610918  ...                  85.659140             3.244839  30.008790  79.928018\n",
       "249468       2020     summer       urad  2.302585  ...                  55.102151             5.963441  30.325565  78.043681\n",
       "\n",
       "[35974 rows x 10 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "450de463-a74e-4487-bbec-c01b1c99fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_encoding  = x_train.copy()\n",
    "x_test_encoding = x_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14c0af9e-8829-4d44-9bff-2a101f3799f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_encoder = LabelEncoder()\n",
    "x_train_encoding['crop_encoded'] = crop_encoder.fit_transform(x_train_encoding['crop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e00fa21d-7ccb-46d7-b23b-d6ef204e64a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_year</th>\n",
       "      <th>season</th>\n",
       "      <th>crop</th>\n",
       "      <th>area</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>relative_humidity_2m_mean</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crop_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>banana</td>\n",
       "      <td>7.367077</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coconut</td>\n",
       "      <td>6.747587</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coriander</td>\n",
       "      <td>8.464214</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>drychillies</td>\n",
       "      <td>8.233769</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>13.539363</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230935</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>24.916359</td>\n",
       "      <td>1.022696</td>\n",
       "      <td>72.918779</td>\n",
       "      <td>9.358756</td>\n",
       "      <td>22.064845</td>\n",
       "      <td>87.837759</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230936</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>5.198497</td>\n",
       "      <td>25.175461</td>\n",
       "      <td>0.705012</td>\n",
       "      <td>61.695276</td>\n",
       "      <td>8.248041</td>\n",
       "      <td>22.420000</td>\n",
       "      <td>87.320000</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230937</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>23.105588</td>\n",
       "      <td>0.319528</td>\n",
       "      <td>65.649194</td>\n",
       "      <td>7.725115</td>\n",
       "      <td>24.174599</td>\n",
       "      <td>88.272133</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230938</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>8.136811</td>\n",
       "      <td>24.080357</td>\n",
       "      <td>0.675058</td>\n",
       "      <td>60.582373</td>\n",
       "      <td>7.733410</td>\n",
       "      <td>23.388409</td>\n",
       "      <td>87.960676</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230939</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>6.959399</td>\n",
       "      <td>24.102247</td>\n",
       "      <td>0.149251</td>\n",
       "      <td>46.248272</td>\n",
       "      <td>7.849136</td>\n",
       "      <td>23.202097</td>\n",
       "      <td>86.322899</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213518 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crop_year     season         crop       area  ...  wind_speed_10m_mean   latitude  longitude  crop_encoded\n",
       "29           2001  wholeyear       banana   7.367077  ...            13.118321  14.724220  77.430674             5\n",
       "30           2001  wholeyear      coconut   6.747587  ...            13.118321  14.724220  77.430674            22\n",
       "31           2001  wholeyear    coriander   8.464214  ...            13.118321  14.724220  77.430674            24\n",
       "4            2001     kharif  drychillies   8.233769  ...            21.165090  14.724220  77.430674            28\n",
       "5            2001     kharif    groundnut  13.539363  ...            21.165090  14.724220  77.430674            34\n",
       "...           ...        ...          ...        ...  ...                  ...        ...        ...           ...\n",
       "230935       2017       rabi        wheat   1.791759  ...             9.358756  22.064845  87.837759            91\n",
       "230936       2017       rabi        wheat   5.198497  ...             8.248041  22.420000  87.320000            91\n",
       "230937       2017       rabi        wheat   4.143135  ...             7.725115  24.174599  88.272133            91\n",
       "230938       2017       rabi        wheat   8.136811  ...             7.733410  23.388409  87.960676            91\n",
       "230939       2017       rabi        wheat   6.959399  ...             7.849136  23.202097  86.322899            91\n",
       "\n",
       "[213518 rows x 11 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "829ba39b-66db-4794-aea0-02dc7825eeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_year</th>\n",
       "      <th>season</th>\n",
       "      <th>crop</th>\n",
       "      <th>area</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>relative_humidity_2m_mean</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>banana</td>\n",
       "      <td>7.367077</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coconut</td>\n",
       "      <td>6.747587</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coriander</td>\n",
       "      <td>8.464214</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>drychillies</td>\n",
       "      <td>8.233769</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>13.539363</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230935</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>24.916359</td>\n",
       "      <td>1.022696</td>\n",
       "      <td>72.918779</td>\n",
       "      <td>9.358756</td>\n",
       "      <td>22.064845</td>\n",
       "      <td>87.837759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230936</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>5.198497</td>\n",
       "      <td>25.175461</td>\n",
       "      <td>0.705012</td>\n",
       "      <td>61.695276</td>\n",
       "      <td>8.248041</td>\n",
       "      <td>22.420000</td>\n",
       "      <td>87.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230937</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>23.105588</td>\n",
       "      <td>0.319528</td>\n",
       "      <td>65.649194</td>\n",
       "      <td>7.725115</td>\n",
       "      <td>24.174599</td>\n",
       "      <td>88.272133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230938</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>8.136811</td>\n",
       "      <td>24.080357</td>\n",
       "      <td>0.675058</td>\n",
       "      <td>60.582373</td>\n",
       "      <td>7.733410</td>\n",
       "      <td>23.388409</td>\n",
       "      <td>87.960676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230939</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>6.959399</td>\n",
       "      <td>24.102247</td>\n",
       "      <td>0.149251</td>\n",
       "      <td>46.248272</td>\n",
       "      <td>7.849136</td>\n",
       "      <td>23.202097</td>\n",
       "      <td>86.322899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213518 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crop_year     season         crop  ...  wind_speed_10m_mean   latitude  longitude\n",
       "29           2001  wholeyear       banana  ...            13.118321  14.724220  77.430674\n",
       "30           2001  wholeyear      coconut  ...            13.118321  14.724220  77.430674\n",
       "31           2001  wholeyear    coriander  ...            13.118321  14.724220  77.430674\n",
       "4            2001     kharif  drychillies  ...            21.165090  14.724220  77.430674\n",
       "5            2001     kharif    groundnut  ...            21.165090  14.724220  77.430674\n",
       "...           ...        ...          ...  ...                  ...        ...        ...\n",
       "230935       2017       rabi        wheat  ...             9.358756  22.064845  87.837759\n",
       "230936       2017       rabi        wheat  ...             8.248041  22.420000  87.320000\n",
       "230937       2017       rabi        wheat  ...             7.725115  24.174599  88.272133\n",
       "230938       2017       rabi        wheat  ...             7.733410  23.388409  87.960676\n",
       "230939       2017       rabi        wheat  ...             7.849136  23.202097  86.322899\n",
       "\n",
       "[213518 rows x 10 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "269fd58a-23ad-4c8a-9226-cb900daee813",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoding['crop_encoded'] = crop_encoder.transform(x_test_encoding['crop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d4aca027-1e83-4079-bffd-837dc7e15a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196293     2\n",
       "196292     2\n",
       "196323     4\n",
       "196322     4\n",
       "196321     4\n",
       "          ..\n",
       "249491    91\n",
       "249460    87\n",
       "249485    91\n",
       "249431    79\n",
       "249468    89\n",
       "Name: crop_encoded, Length: 35974, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_encoding['crop_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3e84d87-9fa4-44c4-a423-a5d5f9a5059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_encoder = LabelEncoder()\n",
    "x_train_encoding['season_encoded'] = season_encoder.fit_transform(x_train_encoding['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb0823f9-cbf8-4624-89db-7e7ede0d9c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29        4\n",
       "30        4\n",
       "31        4\n",
       "4         1\n",
       "5         1\n",
       "         ..\n",
       "230935    2\n",
       "230936    2\n",
       "230937    2\n",
       "230938    2\n",
       "230939    2\n",
       "Name: season_encoded, Length: 213518, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_encoding['season_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf277a88-9d1a-4c66-953d-68a60fe34aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoding['season_encoded'] = season_encoder.transform(x_test_encoding['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78f8f7da-9875-4ef9-9a3f-ac38137dc150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196293    1\n",
       "196292    2\n",
       "196323    1\n",
       "196322    1\n",
       "196321    2\n",
       "         ..\n",
       "249491    2\n",
       "249460    4\n",
       "249485    2\n",
       "249431    1\n",
       "249468    3\n",
       "Name: season_encoded, Length: 35974, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_encoding['season_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c95a836d-c2c6-47c0-a263-e0c15ff1348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_for_scaling = x_train_encoding.drop(['crop','season'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0903a75-76a4-4b7e-8248-d566b7864285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_year</th>\n",
       "      <th>area</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>relative_humidity_2m_mean</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crop_encoded</th>\n",
       "      <th>season_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2001</td>\n",
       "      <td>7.367077</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2001</td>\n",
       "      <td>6.747587</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2001</td>\n",
       "      <td>8.464214</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>8.233769</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>13.539363</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230935</th>\n",
       "      <td>2017</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>24.916359</td>\n",
       "      <td>1.022696</td>\n",
       "      <td>72.918779</td>\n",
       "      <td>9.358756</td>\n",
       "      <td>22.064845</td>\n",
       "      <td>87.837759</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230936</th>\n",
       "      <td>2017</td>\n",
       "      <td>5.198497</td>\n",
       "      <td>25.175461</td>\n",
       "      <td>0.705012</td>\n",
       "      <td>61.695276</td>\n",
       "      <td>8.248041</td>\n",
       "      <td>22.420000</td>\n",
       "      <td>87.320000</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230937</th>\n",
       "      <td>2017</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>23.105588</td>\n",
       "      <td>0.319528</td>\n",
       "      <td>65.649194</td>\n",
       "      <td>7.725115</td>\n",
       "      <td>24.174599</td>\n",
       "      <td>88.272133</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230938</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.136811</td>\n",
       "      <td>24.080357</td>\n",
       "      <td>0.675058</td>\n",
       "      <td>60.582373</td>\n",
       "      <td>7.733410</td>\n",
       "      <td>23.388409</td>\n",
       "      <td>87.960676</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230939</th>\n",
       "      <td>2017</td>\n",
       "      <td>6.959399</td>\n",
       "      <td>24.102247</td>\n",
       "      <td>0.149251</td>\n",
       "      <td>46.248272</td>\n",
       "      <td>7.849136</td>\n",
       "      <td>23.202097</td>\n",
       "      <td>86.322899</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213518 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crop_year       area  temperature_2m_mean  ...  longitude  crop_encoded  season_encoded\n",
       "29           2001   7.367077            26.936137  ...  77.430674             5               4\n",
       "30           2001   6.747587            26.936137  ...  77.430674            22               4\n",
       "31           2001   8.464214            26.936137  ...  77.430674            24               4\n",
       "4            2001   8.233769            27.047742  ...  77.430674            28               1\n",
       "5            2001  13.539363            27.047742  ...  77.430674            34               1\n",
       "...           ...        ...                  ...  ...        ...           ...             ...\n",
       "230935       2017   1.791759            24.916359  ...  87.837759            91               2\n",
       "230936       2017   5.198497            25.175461  ...  87.320000            91               2\n",
       "230937       2017   4.143135            23.105588  ...  88.272133            91               2\n",
       "230938       2017   8.136811            24.080357  ...  87.960676            91               2\n",
       "230939       2017   6.959399            24.102247  ...  86.322899            91               2\n",
       "\n",
       "[213518 rows x 10 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_for_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ac8ffb47-5af9-46de-8199-9bcb1863c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_for_scaling = x_test_encoding.drop(['crop','season'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab21e49c-1818-462b-875c-5470a6d32215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_year</th>\n",
       "      <th>area</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>relative_humidity_2m_mean</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crop_encoded</th>\n",
       "      <th>season_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196293</th>\n",
       "      <td>2018</td>\n",
       "      <td>8.337827</td>\n",
       "      <td>30.524337</td>\n",
       "      <td>1.639104</td>\n",
       "      <td>57.123297</td>\n",
       "      <td>18.537061</td>\n",
       "      <td>14.475294</td>\n",
       "      <td>78.821686</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196292</th>\n",
       "      <td>2018</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>27.324539</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>65.982719</td>\n",
       "      <td>9.026267</td>\n",
       "      <td>16.291519</td>\n",
       "      <td>80.454159</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196323</th>\n",
       "      <td>2018</td>\n",
       "      <td>4.418841</td>\n",
       "      <td>28.712652</td>\n",
       "      <td>8.850824</td>\n",
       "      <td>77.973477</td>\n",
       "      <td>9.236416</td>\n",
       "      <td>18.114126</td>\n",
       "      <td>83.411439</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196322</th>\n",
       "      <td>2018</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>28.544194</td>\n",
       "      <td>9.827921</td>\n",
       "      <td>81.937993</td>\n",
       "      <td>11.404050</td>\n",
       "      <td>18.294931</td>\n",
       "      <td>83.893884</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196321</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>26.882892</td>\n",
       "      <td>0.226152</td>\n",
       "      <td>66.549539</td>\n",
       "      <td>9.343433</td>\n",
       "      <td>14.717439</td>\n",
       "      <td>79.660506</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249491</th>\n",
       "      <td>2020</td>\n",
       "      <td>9.114160</td>\n",
       "      <td>12.551224</td>\n",
       "      <td>2.734038</td>\n",
       "      <td>60.397664</td>\n",
       "      <td>3.186096</td>\n",
       "      <td>30.729860</td>\n",
       "      <td>78.443420</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249460</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>12.463553</td>\n",
       "      <td>6.557644</td>\n",
       "      <td>56.127426</td>\n",
       "      <td>3.479982</td>\n",
       "      <td>30.608720</td>\n",
       "      <td>79.065170</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249485</th>\n",
       "      <td>2020</td>\n",
       "      <td>9.965476</td>\n",
       "      <td>7.998832</td>\n",
       "      <td>2.927197</td>\n",
       "      <td>71.856507</td>\n",
       "      <td>5.530812</td>\n",
       "      <td>29.390529</td>\n",
       "      <td>79.460869</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249431</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>19.961075</td>\n",
       "      <td>13.932401</td>\n",
       "      <td>85.659140</td>\n",
       "      <td>3.244839</td>\n",
       "      <td>30.008790</td>\n",
       "      <td>79.928018</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249468</th>\n",
       "      <td>2020</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>23.703710</td>\n",
       "      <td>1.304355</td>\n",
       "      <td>55.102151</td>\n",
       "      <td>5.963441</td>\n",
       "      <td>30.325565</td>\n",
       "      <td>78.043681</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35974 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crop_year      area  temperature_2m_mean  precipitation_sum  ...   latitude  longitude  crop_encoded  season_encoded\n",
       "196293       2018  8.337827            30.524337           1.639104  ...  14.475294  78.821686             2               1\n",
       "196292       2018  6.966967            27.324539           0.095680  ...  16.291519  80.454159             2               2\n",
       "196323       2018  4.418841            28.712652           8.850824  ...  18.114126  83.411439             4               1\n",
       "196322       2018  4.442651            28.544194           9.827921  ...  18.294931  83.893884             4               1\n",
       "196321       2018  0.693147            26.882892           0.226152  ...  14.717439  79.660506             4               2\n",
       "...           ...       ...                  ...                ...  ...        ...        ...           ...             ...\n",
       "249491       2020  9.114160            12.551224           2.734038  ...  30.729860  78.443420            91               2\n",
       "249460       2020  0.693147            12.463553           6.557644  ...  30.608720  79.065170            87               4\n",
       "249485       2020  9.965476             7.998832           2.927197  ...  29.390529  79.460869            91               2\n",
       "249431       2020  3.610918            19.961075          13.932401  ...  30.008790  79.928018            79               1\n",
       "249468       2020  2.302585            23.703710           1.304355  ...  30.325565  78.043681            89               3\n",
       "\n",
       "[35974 rows x 10 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_for_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b91ae785-bb0e-4302-b6c0-34017ddcfab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_for_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c465b55d-4b80-45ba-9951-e688215b7929",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = scaler.transform(x_test_for_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d74e390-5ec7-4c7f-98a5-fbf5da84408e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from catboost) (2.1.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from catboost) (1.15.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from catboost) (6.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from matplotlib->catboost) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from matplotlib->catboost) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from plotly->catboost) (1.41.0)\n"
     ]
    }
   ],
   "source": [
    "# 1. Catboost model \n",
    "! pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3af82ecf-7c87-4c7f-9130-8a27838fd14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "categorical_features = [\"season\", \"crop\"]\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    bootstrap_type='No',\n",
    "    eval_metric='RMSE',\n",
    "    cat_features=categorical_features,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "19a83af8-da42-4a43-bb38-59b102474fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.1562192\ttest: 1.1781804\tbest: 1.1781804 (0)\ttotal: 333ms\tremaining: 5m 32s\n",
      "100:\tlearn: 0.5441324\ttest: 0.5743583\tbest: 0.5743583 (100)\ttotal: 16.1s\tremaining: 2m 23s\n",
      "200:\tlearn: 0.4984861\ttest: 0.5360666\tbest: 0.5360666 (200)\ttotal: 34.3s\tremaining: 2m 16s\n",
      "300:\tlearn: 0.4712372\ttest: 0.5187391\tbest: 0.5187391 (300)\ttotal: 52.8s\tremaining: 2m 2s\n",
      "400:\tlearn: 0.4524458\ttest: 0.5101981\tbest: 0.5101981 (400)\ttotal: 1m 10s\tremaining: 1m 45s\n",
      "500:\tlearn: 0.4392985\ttest: 0.5036628\tbest: 0.5036628 (500)\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "600:\tlearn: 0.4289233\ttest: 0.4984662\tbest: 0.4984662 (600)\ttotal: 1m 47s\tremaining: 1m 11s\n",
      "700:\tlearn: 0.4202298\ttest: 0.4968824\tbest: 0.4968824 (700)\ttotal: 2m 6s\tremaining: 53.8s\n",
      "800:\tlearn: 0.4115986\ttest: 0.4951120\tbest: 0.4951120 (800)\ttotal: 2m 24s\tremaining: 35.9s\n",
      "900:\tlearn: 0.4053708\ttest: 0.4940487\tbest: 0.4940286 (899)\ttotal: 2m 43s\tremaining: 17.9s\n",
      "999:\tlearn: 0.3986339\ttest: 0.4924781\tbest: 0.4922349 (964)\ttotal: 3m 1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4922348606\n",
      "bestIteration = 964\n",
      "\n",
      "Shrink model to first 965 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2c4f5fe8040>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, eval_set=(x_test, y_test), use_best_model=True, early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29314552-d33c-44e6-aef5-e965f5ac4fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "67c00982-ac2c-4ba8-a4a3-648d487e2f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': {'RMSE': 0.39863390108307817},\n",
       " 'validation': {'RMSE': 0.492234860567333}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14a3b115-81da-4328-9b3f-32cdce7a7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c30af704-cbcd-4fc8-8cc8-1866245acf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b8fb3459-987c-4949-9508-b0586f360354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24229515799784115, 0.15669704318696648)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = mean_squared_error(y_test,y_test_predict)\n",
    "train_score = mean_squared_error(y_train,y_train_predict)\n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bcdd2b6b-f947-4a30-b3bc-dcf87718f95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8344231539413826, 0.8894671670044105)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r2 = r2_score(y_test,y_test_predict)\n",
    "train_r2 = r2_score(y_train,y_train_predict)\n",
    "test_r2,train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d1a0128-6937-443b-8ca2-b7eed45dc41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "test_pool = Pool(data=x_test, label=y_test, cat_features=categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de37ef27-bc81-49f5-8e9f-91604069314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    depth=6,\n",
    "    eval_metric='RMSE',\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "61ebac85-1b6b-4b15-9403-dc245417eb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.1219263\ttest: 1.1467497\tbest: 1.1467497 (0)\ttotal: 190ms\tremaining: 3m 9s\n",
      "100:\tlearn: 0.4941229\ttest: 0.5383037\tbest: 0.5383037 (100)\ttotal: 17.3s\tremaining: 2m 34s\n",
      "200:\tlearn: 0.4525156\ttest: 0.5126138\tbest: 0.5126138 (200)\ttotal: 35s\tremaining: 2m 19s\n",
      "300:\tlearn: 0.4265129\ttest: 0.5009766\tbest: 0.5009766 (300)\ttotal: 53s\tremaining: 2m 3s\n",
      "400:\tlearn: 0.4080265\ttest: 0.4961881\tbest: 0.4960502 (378)\ttotal: 1m 11s\tremaining: 1m 47s\n",
      "500:\tlearn: 0.3955195\ttest: 0.4942149\tbest: 0.4937850 (452)\ttotal: 1m 30s\tremaining: 1m 29s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.4937849753\n",
      "bestIteration = 452\n",
      "\n",
      "Shrink model to first 453 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2c4f5fd4e50>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool.fit(train_pool, eval_set=test_pool, use_best_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d9f94fe9-edf6-4652-9833-c8e5488c9182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn': {'RMSE': 0.3953887533804206},\n",
       " 'validation': {'RMSE': 0.49378497530082255}}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "376b0a52-7363-4ecc-82aa-41295c49f5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2438236020541351, 0.15673922163963072)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pool_predict = model_pool.predict(test_pool) \n",
    "y_train_pool_predict = model_pool.predict(train_pool)\n",
    "test_pool_score = mean_squared_error(y_test,y_test_pool_predict)\n",
    "train_pool_score = mean_squared_error(y_train,y_train_pool_predict)\n",
    "test_pool_score,train_pool_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04370ddd-00f4-4eaf-b347-c52edf1120d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.83337866362507, 0.8894374146633993)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r2 = r2_score(y_test,y_test_pool_predict)\n",
    "train_r2 = r2_score(y_train,y_train_pool_predict)\n",
    "test_r2,train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77a79d47-5a86-4687-8174-e08ced5457fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from lightgbm) (2.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from lightgbm) (1.15.3)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 0.8/1.5 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "# 2. LightGBM \n",
    "! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a2d82129-1e3f-4740-8870-050e57d313b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b6475889-bb17-4a66-89fb-9e322a826523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical columns to 'category' dtype\n",
    "for col in ['crop', 'season']:\n",
    "    x_train[col] = x_train[col].astype('category')\n",
    "    x_test[col] = x_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f198e66-526c-4c7a-a9d7-434b721fd72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6a533db3-4d2b-45af-a70f-cb8046f52c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_year</th>\n",
       "      <th>season</th>\n",
       "      <th>crop</th>\n",
       "      <th>area</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>relative_humidity_2m_mean</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>banana</td>\n",
       "      <td>7.367077</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coconut</td>\n",
       "      <td>6.747587</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2001</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>coriander</td>\n",
       "      <td>8.464214</td>\n",
       "      <td>26.936137</td>\n",
       "      <td>1.614875</td>\n",
       "      <td>58.895437</td>\n",
       "      <td>13.118321</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>drychillies</td>\n",
       "      <td>8.233769</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2001</td>\n",
       "      <td>kharif</td>\n",
       "      <td>groundnut</td>\n",
       "      <td>13.539363</td>\n",
       "      <td>27.047742</td>\n",
       "      <td>1.125806</td>\n",
       "      <td>65.310753</td>\n",
       "      <td>21.165090</td>\n",
       "      <td>14.724220</td>\n",
       "      <td>77.430674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230935</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>24.916359</td>\n",
       "      <td>1.022696</td>\n",
       "      <td>72.918779</td>\n",
       "      <td>9.358756</td>\n",
       "      <td>22.064845</td>\n",
       "      <td>87.837759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230936</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>5.198497</td>\n",
       "      <td>25.175461</td>\n",
       "      <td>0.705012</td>\n",
       "      <td>61.695276</td>\n",
       "      <td>8.248041</td>\n",
       "      <td>22.420000</td>\n",
       "      <td>87.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230937</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>4.143135</td>\n",
       "      <td>23.105588</td>\n",
       "      <td>0.319528</td>\n",
       "      <td>65.649194</td>\n",
       "      <td>7.725115</td>\n",
       "      <td>24.174599</td>\n",
       "      <td>88.272133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230938</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>8.136811</td>\n",
       "      <td>24.080357</td>\n",
       "      <td>0.675058</td>\n",
       "      <td>60.582373</td>\n",
       "      <td>7.733410</td>\n",
       "      <td>23.388409</td>\n",
       "      <td>87.960676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230939</th>\n",
       "      <td>2017</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>6.959399</td>\n",
       "      <td>24.102247</td>\n",
       "      <td>0.149251</td>\n",
       "      <td>46.248272</td>\n",
       "      <td>7.849136</td>\n",
       "      <td>23.202097</td>\n",
       "      <td>86.322899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213518 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crop_year     season         crop  ...  wind_speed_10m_mean   latitude  longitude\n",
       "29           2001  wholeyear       banana  ...            13.118321  14.724220  77.430674\n",
       "30           2001  wholeyear      coconut  ...            13.118321  14.724220  77.430674\n",
       "31           2001  wholeyear    coriander  ...            13.118321  14.724220  77.430674\n",
       "4            2001     kharif  drychillies  ...            21.165090  14.724220  77.430674\n",
       "5            2001     kharif    groundnut  ...            21.165090  14.724220  77.430674\n",
       "...           ...        ...          ...  ...                  ...        ...        ...\n",
       "230935       2017       rabi        wheat  ...             9.358756  22.064845  87.837759\n",
       "230936       2017       rabi        wheat  ...             8.248041  22.420000  87.320000\n",
       "230937       2017       rabi        wheat  ...             7.725115  24.174599  88.272133\n",
       "230938       2017       rabi        wheat  ...             7.733410  23.388409  87.960676\n",
       "230939       2017       rabi        wheat  ...             7.849136  23.202097  86.322899\n",
       "\n",
       "[213518 rows x 10 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ce567dd4-8803-4a75-9e7a-fb5b79e004cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1901\n",
      "[LightGBM] [Info] Number of data points in the train set: 213518, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 1.184515\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(objective=&#x27;regression&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMRegressor</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(objective=&#x27;regression&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(objective='regression')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ba582061-d84d-462a-a321-eab1ce716835",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_lgbm_predict = model_lgbm.predict(x_test)\n",
    "y_train_lgbm_predict = model_lgbm.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0db6c79e-2250-496a-9fa6-61ec08584bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8400751331111764, 0.9077156869663902)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_test_lgbm = r2_score(y_test,y_test_lgbm_predict)\n",
    "r2_train_lgbm = r2_score(y_train,y_train_lgbm_predict)\n",
    "r2_test_lgbm, r2_train_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9c89483a-1631-4fe1-b43d-ffa0fe8cd528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48376067738212264, 0.3617001525923697)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_test_lgbm = root_mean_squared_error(y_test,y_test_lgbm_predict)\n",
    "rmse_train_lgbm = root_mean_squared_error(y_train,y_train_lgbm_predict)\n",
    "rmse_test_lgbm, rmse_train_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "780ac545-b27f-4942-ae55-e791c0880c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot predictions vs actual\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_lgbm_predict, alpha=0.4, color='royalblue')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('LigthGBM - Actual vs Predicted')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62820b53-298c-4487-bfa0-cd328b8c678b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from xgboost) (2.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Downloading xgboost-3.0.2-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/150.0 MB 4.8 MB/s eta 0:00:32\n",
      "   ---------------------------------------- 1.6/150.0 MB 4.9 MB/s eta 0:00:31\n",
      "    --------------------------------------- 2.4/150.0 MB 4.2 MB/s eta 0:00:36\n",
      "    --------------------------------------- 3.1/150.0 MB 4.0 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 4.2/150.0 MB 4.1 MB/s eta 0:00:36\n",
      "   - -------------------------------------- 5.2/150.0 MB 4.2 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 6.3/150.0 MB 4.3 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 7.3/150.0 MB 4.3 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 8.4/150.0 MB 4.4 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 9.4/150.0 MB 4.5 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 10.5/150.0 MB 4.5 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 11.8/150.0 MB 4.6 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 12.8/150.0 MB 4.7 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 13.9/150.0 MB 4.7 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 14.9/150.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 16.0/150.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 17.0/150.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 17.8/150.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 18.9/150.0 MB 4.7 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 19.9/150.0 MB 4.6 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 20.7/150.0 MB 4.6 MB/s eta 0:00:28\n",
      "   ----- ---------------------------------- 22.0/150.0 MB 4.7 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 23.1/150.0 MB 4.7 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 24.4/150.0 MB 4.7 MB/s eta 0:00:27\n",
      "   ------ --------------------------------- 25.2/150.0 MB 4.7 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 26.5/150.0 MB 4.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 27.8/150.0 MB 4.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 28.8/150.0 MB 4.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 29.9/150.0 MB 4.8 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 30.9/150.0 MB 4.8 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 32.0/150.0 MB 4.8 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 33.0/150.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 34.1/150.0 MB 4.8 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 35.1/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 35.9/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 37.2/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 38.3/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 39.1/150.0 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 40.4/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 41.2/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 42.5/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 43.5/150.0 MB 4.8 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 44.6/150.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 45.6/150.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 46.9/150.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 48.0/150.0 MB 4.8 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 49.3/150.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 50.6/150.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 51.6/150.0 MB 4.9 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 53.0/150.0 MB 4.9 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 54.0/150.0 MB 4.9 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 55.1/150.0 MB 4.9 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 56.4/150.0 MB 4.9 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 57.4/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 58.5/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 59.2/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 60.3/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 61.3/150.0 MB 4.9 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 62.4/150.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 63.7/150.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 64.7/150.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 66.1/150.0 MB 4.9 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 67.1/150.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 68.2/150.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 69.5/150.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 70.8/150.0 MB 4.9 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 71.8/150.0 MB 4.9 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 72.9/150.0 MB 5.0 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 74.2/150.0 MB 5.0 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 75.2/150.0 MB 5.0 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 76.3/150.0 MB 5.0 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 77.3/150.0 MB 5.0 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 78.6/150.0 MB 5.0 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 79.7/150.0 MB 5.0 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 80.7/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 82.1/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 83.1/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 84.1/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 85.2/150.0 MB 5.0 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 86.5/150.0 MB 5.0 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 87.3/150.0 MB 5.0 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 88.6/150.0 MB 5.0 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 89.7/150.0 MB 5.0 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 91.0/150.0 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 92.0/150.0 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 93.1/150.0 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 94.1/150.0 MB 5.0 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 95.4/150.0 MB 5.0 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 96.5/150.0 MB 5.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 97.8/150.0 MB 5.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 98.8/150.0 MB 5.0 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 100.1/150.0 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 101.4/150.0 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 102.5/150.0 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 103.5/150.0 MB 5.0 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 104.9/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 105.9/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 107.0/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 108.0/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 109.1/150.0 MB 5.0 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 110.1/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 110.9/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 112.2/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 113.0/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 114.3/150.0 MB 5.0 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 115.3/150.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 116.7/150.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 117.7/150.0 MB 5.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 119.0/150.0 MB 5.0 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 120.1/150.0 MB 5.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 121.1/150.0 MB 5.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 122.4/150.0 MB 5.0 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 123.5/150.0 MB 5.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 124.8/150.0 MB 5.0 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 126.1/150.0 MB 5.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 127.1/150.0 MB 5.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 128.5/150.0 MB 5.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 129.5/150.0 MB 5.1 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 130.8/150.0 MB 5.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 131.9/150.0 MB 5.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 132.9/150.0 MB 5.1 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 134.0/150.0 MB 5.1 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 135.0/150.0 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 136.3/150.0 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 137.4/150.0 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 138.7/150.0 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 139.7/150.0 MB 5.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 140.8/150.0 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 142.1/150.0 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 143.1/150.0 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 144.2/150.0 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 145.5/150.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  146.5/150.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  147.6/150.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  148.6/150.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.4/150.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.9/150.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.9/150.0 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 150.0/150.0 MB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.2\n"
     ]
    }
   ],
   "source": [
    "# 3. XGBoostRegression\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c6011799-8ded-455a-a6a4-d6503ae3918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7002bbcb-9eae-4683-8a64-9b19b56f8eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = XGBRegressor(objective='reg:squarederror', enable_categorical=True, tree_method='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b27c4f62-6c85-4e84-b0fa-25bcf037a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid parameters\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [50, 100],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "12fab122-303a-4ab2-a76e-7830d8248bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = GridSearchCV(estimator=reg, param_grid=param_grid, \n",
    "                           cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "05c4d678-4064-4861-b88d-8b2c5c277d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.79478342,  0.19187274,  0.38720255, ..., -0.59759759,\n",
       "        -1.83358182,  1.4884182 ],\n",
       "       [-1.79478342, -0.04605105,  0.38720255, ..., -0.59759759,\n",
       "        -1.17434485,  1.4884182 ],\n",
       "       [-1.79478342,  0.61324324,  0.38720255, ..., -0.59759759,\n",
       "        -1.09678756,  1.4884182 ],\n",
       "       ...,\n",
       "       [ 1.42482539, -1.04632629, -0.51820785, ...,  1.21620329,\n",
       "         1.50138164, -0.09991126],\n",
       "       [ 1.42482539,  0.4874995 , -0.2878058 , ...,  1.16409579,\n",
       "         1.50138164, -0.09991126],\n",
       "       [ 1.42482539,  0.03529823, -0.2826319 , ...,  0.89009189,\n",
       "         1.50138164, -0.09991126]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b6f48dc0-d398-470b-9cbd-0ca309ac6049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=True, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None,...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [4, 6, 8],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100], &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=True, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None,...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [4, 6, 8],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100], &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=8,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=True, eval_metric=None,\n",
       "                                    feature_types=None, feature_weights=None,\n",
       "                                    gamma=None, grow_policy=None,\n",
       "                                    importance_type=None,\n",
       "                                    interaction_constraints=None,...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None,\n",
       "                                    multi_strategy=None, n_estimators=None,\n",
       "                                    n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.05, 0.1], 'max_depth': [4, 6, 8],\n",
       "                         'n_estimators': [50, 100], 'subsample': [0.8, 1.0]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e503a228-ce9c-4059-ba6c-318840a56d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_xgb_predict = model_xgb.predict(x_test_scaled)\n",
    "y_train_xgb_predict = model_xgb.predict(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6f45bfbb-4220-4107-b669-def18ca42567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8356979245790025, 0.9353331246920542)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_test_xgb = r2_score(y_test,y_test_xgb_predict)\n",
    "r2_train_xgb = r2_score(y_train,y_train_xgb_predict)\n",
    "r2_test_xgb, r2_train_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c198dd8-f60e-4b6c-a317-56ac62388d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.2-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.1.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.13.0-cp310-cp310-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.16.0-cp310-cp310-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\91742\\desktop\\indian_agriculture\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\91742\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.19.0-cp310-cp310-win_amd64.whl (375.7 MB)\n",
      "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Using cached h5py-3.13.0-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.3/1.4 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 0.8/1.4 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 2.6 MB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl (209 kB)\n",
      "Downloading numpy-2.1.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.9 MB 2.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.3/12.9 MB 3.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.4/12.9 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 4.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.7/12.9 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.8/12.9 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.8/12.9 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.1/12.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.9 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 5.2 MB/s eta 0:00:00\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.5-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp310-cp310-win_amd64.whl (304 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.4\n",
      "    Uninstalling numpy-2.2.4:\n",
      "      Successfully uninstalled numpy-2.2.4\n",
      "Successfully installed absl-py-2.3.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.10.0 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.1.0 numpy-2.1.3 opt-einsum-3.4.0 optree-0.16.0 protobuf-5.29.5 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "# 4. Neural network \n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5d636527-52b2-4cf9-9bf2-132f41b97516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout,Input,LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "67c52baf-56a8-4519-82a9-48436192a735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91742\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_nn = Sequential([\n",
    "    Dense(128, input_dim=10, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1)\n",
    "    \n",
    "    ])\n",
    "model_nn.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae','r2_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1e832461-18a1-4639-a3d8-17ba08f8ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "66fd9bd0-8452-4bce-abd9-3c250955678c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - loss: 1.5245 - mae: 0.7954 - r2_score: -0.1100 - val_loss: 1.0746 - val_mae: 0.6554 - val_r2_score: 0.2656\n",
      "Epoch 2/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 1.0119 - mae: 0.6326 - r2_score: 0.2786 - val_loss: 0.9086 - val_mae: 0.6256 - val_r2_score: 0.3791\n",
      "Epoch 3/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.9197 - mae: 0.6119 - r2_score: 0.3573 - val_loss: 0.8674 - val_mae: 0.6040 - val_r2_score: 0.4072\n",
      "Epoch 4/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - loss: 0.8288 - mae: 0.5903 - r2_score: 0.4124 - val_loss: 0.7533 - val_mae: 0.5851 - val_r2_score: 0.4852\n",
      "Epoch 5/100\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 0.8450 - mae: 0.5922 - r2_score: 0.4070 - val_loss: 0.7501 - val_mae: 0.5923 - val_r2_score: 0.4874\n",
      "Epoch 6/100\n",
      "\u001b[1m 37/418\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.7800 - mae: 0.5898 - r2_score: 0.4411"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_nn.fit(\n",
    "    x_train_scaled, y_train,\n",
    "    validation_data=(x_test_scaled, y_test),\n",
    "    epochs=100,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "098f9aed-2ab0-420e-9b88-e0feecae33b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "\u001b[1m6673/6673\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_nn_predict = model_nn.predict(x_test_scaled)\n",
    "y_train_nn_predict = model_nn.predict(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "728a5657-a236-4264-91bc-833f9e1d6470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6722139238830488, 0.7414490216560512)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_test_nn = r2_score(y_test,y_test_nn_predict)\n",
    "r2_train_nn = r2_score(y_train,y_train_nn_predict)\n",
    "r2_test_nn, r2_train_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6714c66-f405-4310-a246-9ed0af203763",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, Y_val, Y_test = train_test_split(x_test_for_scaling, y_test, test_size=0.5, random_state=42)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c405e86f-d6d6-4df2-bbdd-5e9d22a24a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = x_train_scaled.reshape((x_train_scaled.shape[0], 1, x_train_scaled.shape[1]))\n",
    "X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f2c7c3e0-9a49-491e-8e40-623bf7e31dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.5181 - mae: 1.1164\n",
      "Epoch 1: val_loss improved from inf to 1.35680, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - loss: 2.5119 - mae: 1.1145 - val_loss: 1.3568 - val_mae: 0.6943 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2507 - mae: 0.7303\n",
      "Epoch 2: val_loss improved from 1.35680 to 1.22170, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - loss: 1.2505 - mae: 0.7303 - val_loss: 1.2217 - val_mae: 0.6541 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.1383 - mae: 0.6891\n",
      "Epoch 3: val_loss improved from 1.22170 to 1.08005, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 1.1383 - mae: 0.6890 - val_loss: 1.0801 - val_mae: 0.6323 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0578 - mae: 0.6621\n",
      "Epoch 4: val_loss improved from 1.08005 to 1.04095, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 1.0578 - mae: 0.6621 - val_loss: 1.0410 - val_mae: 0.6301 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0501 - mae: 0.6513\n",
      "Epoch 5: val_loss improved from 1.04095 to 1.01330, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 1.0500 - mae: 0.6513 - val_loss: 1.0133 - val_mae: 0.6253 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0237 - mae: 0.6406\n",
      "Epoch 6: val_loss improved from 1.01330 to 0.98132, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 1.0236 - mae: 0.6406 - val_loss: 0.9813 - val_mae: 0.6191 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.9982 - mae: 0.6350\n",
      "Epoch 7: val_loss improved from 0.98132 to 0.94556, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 0.9980 - mae: 0.6349 - val_loss: 0.9456 - val_mae: 0.6081 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.9324 - mae: 0.6184\n",
      "Epoch 8: val_loss improved from 0.94556 to 0.88372, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.9324 - mae: 0.6184 - val_loss: 0.8837 - val_mae: 0.6072 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.8797 - mae: 0.6051\n",
      "Epoch 9: val_loss improved from 0.88372 to 0.87301, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.8796 - mae: 0.6051 - val_loss: 0.8730 - val_mae: 0.5965 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.8485 - mae: 0.5957\n",
      "Epoch 10: val_loss improved from 0.87301 to 0.74700, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.8484 - mae: 0.5957 - val_loss: 0.7470 - val_mae: 0.5749 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.8087 - mae: 0.5869\n",
      "Epoch 11: val_loss improved from 0.74700 to 0.73596, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.8087 - mae: 0.5869 - val_loss: 0.7360 - val_mae: 0.5729 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.7838 - mae: 0.5778\n",
      "Epoch 12: val_loss improved from 0.73596 to 0.71269, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.7838 - mae: 0.5778 - val_loss: 0.7127 - val_mae: 0.5660 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.7655 - mae: 0.5742\n",
      "Epoch 13: val_loss did not improve from 0.71269\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 0.7656 - mae: 0.5742 - val_loss: 0.7180 - val_mae: 0.5653 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.7616 - mae: 0.5706\n",
      "Epoch 14: val_loss improved from 0.71269 to 0.69241, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - loss: 0.7616 - mae: 0.5706 - val_loss: 0.6924 - val_mae: 0.5584 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.7319 - mae: 0.5615\n",
      "Epoch 15: val_loss improved from 0.69241 to 0.68034, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 0.7319 - mae: 0.5615 - val_loss: 0.6803 - val_mae: 0.5510 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.7344 - mae: 0.5604\n",
      "Epoch 16: val_loss improved from 0.68034 to 0.67208, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.7342 - mae: 0.5603 - val_loss: 0.6721 - val_mae: 0.5454 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.7079 - mae: 0.5517\n",
      "Epoch 17: val_loss improved from 0.67208 to 0.67079, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.7079 - mae: 0.5517 - val_loss: 0.6708 - val_mae: 0.5409 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.7016 - mae: 0.5473\n",
      "Epoch 18: val_loss improved from 0.67079 to 0.64739, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 0.7015 - mae: 0.5472 - val_loss: 0.6474 - val_mae: 0.5398 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6904 - mae: 0.5441\n",
      "Epoch 19: val_loss improved from 0.64739 to 0.64012, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.6904 - mae: 0.5441 - val_loss: 0.6401 - val_mae: 0.5349 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.6818 - mae: 0.5405\n",
      "Epoch 20: val_loss improved from 0.64012 to 0.63771, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.6818 - mae: 0.5405 - val_loss: 0.6377 - val_mae: 0.5305 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.6577 - mae: 0.5331\n",
      "Epoch 21: val_loss improved from 0.63771 to 0.63381, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.6577 - mae: 0.5331 - val_loss: 0.6338 - val_mae: 0.5257 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6571 - mae: 0.5315\n",
      "Epoch 22: val_loss improved from 0.63381 to 0.61659, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.6571 - mae: 0.5315 - val_loss: 0.6166 - val_mae: 0.5166 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6484 - mae: 0.5278\n",
      "Epoch 23: val_loss did not improve from 0.61659\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 0.6484 - mae: 0.5278 - val_loss: 0.6203 - val_mae: 0.5180 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6308 - mae: 0.5231\n",
      "Epoch 24: val_loss improved from 0.61659 to 0.61231, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.6308 - mae: 0.5231 - val_loss: 0.6123 - val_mae: 0.5145 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6219 - mae: 0.5195\n",
      "Epoch 25: val_loss improved from 0.61231 to 0.60944, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.6219 - mae: 0.5195 - val_loss: 0.6094 - val_mae: 0.5092 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6245 - mae: 0.5152\n",
      "Epoch 26: val_loss improved from 0.60944 to 0.60082, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.6244 - mae: 0.5152 - val_loss: 0.6008 - val_mae: 0.5011 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.6098 - mae: 0.5105\n",
      "Epoch 27: val_loss improved from 0.60082 to 0.59963, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 0.6098 - mae: 0.5105 - val_loss: 0.5996 - val_mae: 0.4993 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6055 - mae: 0.5095\n",
      "Epoch 28: val_loss did not improve from 0.59963\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.6055 - mae: 0.5095 - val_loss: 0.6018 - val_mae: 0.4948 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5870 - mae: 0.5027\n",
      "Epoch 29: val_loss improved from 0.59963 to 0.59753, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.5871 - mae: 0.5028 - val_loss: 0.5975 - val_mae: 0.4977 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5849 - mae: 0.5024\n",
      "Epoch 30: val_loss did not improve from 0.59753\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.5850 - mae: 0.5024 - val_loss: 0.6066 - val_mae: 0.4956 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5837 - mae: 0.5002\n",
      "Epoch 31: val_loss did not improve from 0.59753\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.5838 - mae: 0.5002 - val_loss: 0.6077 - val_mae: 0.4907 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5831 - mae: 0.4948\n",
      "Epoch 32: val_loss improved from 0.59753 to 0.57054, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 0.5831 - mae: 0.4948 - val_loss: 0.5705 - val_mae: 0.4892 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5736 - mae: 0.4971\n",
      "Epoch 33: val_loss did not improve from 0.57054\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.5736 - mae: 0.4971 - val_loss: 0.6196 - val_mae: 0.4891 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5760 - mae: 0.4930\n",
      "Epoch 34: val_loss did not improve from 0.57054\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.5759 - mae: 0.4930 - val_loss: 0.5742 - val_mae: 0.4828 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5543 - mae: 0.4870\n",
      "Epoch 35: val_loss did not improve from 0.57054\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.5543 - mae: 0.4870 - val_loss: 0.5952 - val_mae: 0.4805 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.5488 - mae: 0.4822\n",
      "Epoch 36: val_loss improved from 0.57054 to 0.56065, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.5488 - mae: 0.4823 - val_loss: 0.5606 - val_mae: 0.4753 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5458 - mae: 0.4822\n",
      "Epoch 37: val_loss improved from 0.56065 to 0.54583, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.5458 - mae: 0.4822 - val_loss: 0.5458 - val_mae: 0.4707 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5327 - mae: 0.4786\n",
      "Epoch 38: val_loss did not improve from 0.54583\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.5328 - mae: 0.4786 - val_loss: 0.5597 - val_mae: 0.4689 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5302 - mae: 0.4749\n",
      "Epoch 39: val_loss did not improve from 0.54583\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.5303 - mae: 0.4749 - val_loss: 0.5564 - val_mae: 0.4650 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5446 - mae: 0.4768\n",
      "Epoch 40: val_loss did not improve from 0.54583\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.5446 - mae: 0.4769 - val_loss: 0.5607 - val_mae: 0.4648 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5255 - mae: 0.4734\n",
      "Epoch 41: val_loss improved from 0.54583 to 0.54191, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 0.5255 - mae: 0.4734 - val_loss: 0.5419 - val_mae: 0.4695 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5270 - mae: 0.4725\n",
      "Epoch 42: val_loss did not improve from 0.54191\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 0.5270 - mae: 0.4725 - val_loss: 0.5442 - val_mae: 0.4583 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5109 - mae: 0.4673\n",
      "Epoch 43: val_loss did not improve from 0.54191\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.5109 - mae: 0.4673 - val_loss: 0.5432 - val_mae: 0.4564 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5122 - mae: 0.4676\n",
      "Epoch 44: val_loss did not improve from 0.54191\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 0.5123 - mae: 0.4676 - val_loss: 0.5551 - val_mae: 0.4556 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.5052 - mae: 0.4656\n",
      "Epoch 45: val_loss did not improve from 0.54191\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.5052 - mae: 0.4656 - val_loss: 0.5435 - val_mae: 0.4529 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5165 - mae: 0.4667\n",
      "Epoch 46: val_loss improved from 0.54191 to 0.53223, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 0.5165 - mae: 0.4667 - val_loss: 0.5322 - val_mae: 0.4543 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5093 - mae: 0.4638\n",
      "Epoch 47: val_loss did not improve from 0.53223\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.5093 - mae: 0.4638 - val_loss: 0.5687 - val_mae: 0.4566 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5043 - mae: 0.4617\n",
      "Epoch 48: val_loss improved from 0.53223 to 0.52860, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.5043 - mae: 0.4617 - val_loss: 0.5286 - val_mae: 0.4480 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4925 - mae: 0.4605\n",
      "Epoch 49: val_loss did not improve from 0.52860\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.4925 - mae: 0.4605 - val_loss: 0.5360 - val_mae: 0.4533 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4897 - mae: 0.4587\n",
      "Epoch 50: val_loss improved from 0.52860 to 0.51775, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.4897 - mae: 0.4587 - val_loss: 0.5178 - val_mae: 0.4422 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4853 - mae: 0.4550\n",
      "Epoch 51: val_loss did not improve from 0.51775\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 0.4854 - mae: 0.4550 - val_loss: 0.5246 - val_mae: 0.4462 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4965 - mae: 0.4579\n",
      "Epoch 52: val_loss did not improve from 0.51775\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.4965 - mae: 0.4579 - val_loss: 0.5197 - val_mae: 0.4446 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4964 - mae: 0.4571\n",
      "Epoch 53: val_loss improved from 0.51775 to 0.51639, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 0.4963 - mae: 0.4571 - val_loss: 0.5164 - val_mae: 0.4433 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4873 - mae: 0.4554\n",
      "Epoch 54: val_loss improved from 0.51639 to 0.50350, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.4873 - mae: 0.4554 - val_loss: 0.5035 - val_mae: 0.4395 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4882 - mae: 0.4535\n",
      "Epoch 55: val_loss improved from 0.50350 to 0.50227, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.4881 - mae: 0.4535 - val_loss: 0.5023 - val_mae: 0.4413 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4823 - mae: 0.4523\n",
      "Epoch 56: val_loss did not improve from 0.50227\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.4823 - mae: 0.4523 - val_loss: 0.5182 - val_mae: 0.4419 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4814 - mae: 0.4505\n",
      "Epoch 57: val_loss improved from 0.50227 to 0.49819, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.4814 - mae: 0.4505 - val_loss: 0.4982 - val_mae: 0.4426 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4795 - mae: 0.4495\n",
      "Epoch 58: val_loss did not improve from 0.49819\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.4795 - mae: 0.4495 - val_loss: 0.5319 - val_mae: 0.4412 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4781 - mae: 0.4504\n",
      "Epoch 59: val_loss improved from 0.49819 to 0.48931, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.4781 - mae: 0.4504 - val_loss: 0.4893 - val_mae: 0.4345 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4715 - mae: 0.4483\n",
      "Epoch 60: val_loss did not improve from 0.48931\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.4714 - mae: 0.4483 - val_loss: 0.5096 - val_mae: 0.4420 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4731 - mae: 0.4473\n",
      "Epoch 61: val_loss did not improve from 0.48931\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.4731 - mae: 0.4473 - val_loss: 0.4925 - val_mae: 0.4400 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4622 - mae: 0.4449\n",
      "Epoch 62: val_loss did not improve from 0.48931\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 0.4622 - mae: 0.4450 - val_loss: 0.5161 - val_mae: 0.4360 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4639 - mae: 0.4438\n",
      "Epoch 63: val_loss did not improve from 0.48931\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 0.4639 - mae: 0.4438 - val_loss: 0.4974 - val_mae: 0.4353 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4612 - mae: 0.4436\n",
      "Epoch 64: val_loss improved from 0.48931 to 0.48565, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.4612 - mae: 0.4436 - val_loss: 0.4856 - val_mae: 0.4331 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4702 - mae: 0.4456\n",
      "Epoch 65: val_loss did not improve from 0.48565\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.4701 - mae: 0.4456 - val_loss: 0.4880 - val_mae: 0.4299 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4517 - mae: 0.4411\n",
      "Epoch 66: val_loss improved from 0.48565 to 0.48093, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.4517 - mae: 0.4411 - val_loss: 0.4809 - val_mae: 0.4389 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4532 - mae: 0.4399\n",
      "Epoch 67: val_loss did not improve from 0.48093\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 0.4532 - mae: 0.4399 - val_loss: 0.4826 - val_mae: 0.4229 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4488 - mae: 0.4372\n",
      "Epoch 68: val_loss did not improve from 0.48093\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 34ms/step - loss: 0.4489 - mae: 0.4372 - val_loss: 0.4888 - val_mae: 0.4265 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4528 - mae: 0.4370\n",
      "Epoch 69: val_loss improved from 0.48093 to 0.47087, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.4528 - mae: 0.4370 - val_loss: 0.4709 - val_mae: 0.4188 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4441 - mae: 0.4343\n",
      "Epoch 70: val_loss did not improve from 0.47087\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.4441 - mae: 0.4343 - val_loss: 0.4906 - val_mae: 0.4293 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4442 - mae: 0.4343\n",
      "Epoch 71: val_loss did not improve from 0.47087\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.4442 - mae: 0.4343 - val_loss: 0.4715 - val_mae: 0.4204 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4361 - mae: 0.4306\n",
      "Epoch 72: val_loss did not improve from 0.47087\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.4362 - mae: 0.4306 - val_loss: 0.4728 - val_mae: 0.4218 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4572 - mae: 0.4358\n",
      "Epoch 73: val_loss improved from 0.47087 to 0.47041, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 0.4571 - mae: 0.4358 - val_loss: 0.4704 - val_mae: 0.4150 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4407 - mae: 0.4296\n",
      "Epoch 74: val_loss did not improve from 0.47041\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.4407 - mae: 0.4296 - val_loss: 0.4802 - val_mae: 0.4211 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4452 - mae: 0.4303\n",
      "Epoch 75: val_loss improved from 0.47041 to 0.46597, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 0.4451 - mae: 0.4303 - val_loss: 0.4660 - val_mae: 0.4144 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4462 - mae: 0.4299\n",
      "Epoch 76: val_loss did not improve from 0.46597\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.4461 - mae: 0.4299 - val_loss: 0.4684 - val_mae: 0.4110 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4322 - mae: 0.4273\n",
      "Epoch 77: val_loss did not improve from 0.46597\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.4323 - mae: 0.4273 - val_loss: 0.4674 - val_mae: 0.4126 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4324 - mae: 0.4283\n",
      "Epoch 78: val_loss did not improve from 0.46597\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.4324 - mae: 0.4283 - val_loss: 0.4759 - val_mae: 0.4211 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4406 - mae: 0.4274\n",
      "Epoch 79: val_loss improved from 0.46597 to 0.45716, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.4405 - mae: 0.4273 - val_loss: 0.4572 - val_mae: 0.4152 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4529 - mae: 0.4290\n",
      "Epoch 80: val_loss did not improve from 0.45716\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.4528 - mae: 0.4290 - val_loss: 0.4669 - val_mae: 0.4114 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4276 - mae: 0.4241\n",
      "Epoch 81: val_loss did not improve from 0.45716\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.4276 - mae: 0.4241 - val_loss: 0.4611 - val_mae: 0.4095 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4280 - mae: 0.4221\n",
      "Epoch 82: val_loss did not improve from 0.45716\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 0.4279 - mae: 0.4221 - val_loss: 0.4623 - val_mae: 0.4083 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4209 - mae: 0.4216\n",
      "Epoch 83: val_loss improved from 0.45716 to 0.45355, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.4209 - mae: 0.4216 - val_loss: 0.4536 - val_mae: 0.4092 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4305 - mae: 0.4231\n",
      "Epoch 84: val_loss did not improve from 0.45355\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.4305 - mae: 0.4231 - val_loss: 0.4576 - val_mae: 0.4087 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4163 - mae: 0.4181\n",
      "Epoch 85: val_loss improved from 0.45355 to 0.44585, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 0.4163 - mae: 0.4181 - val_loss: 0.4458 - val_mae: 0.4071 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4341 - mae: 0.4231\n",
      "Epoch 86: val_loss did not improve from 0.44585\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.4340 - mae: 0.4231 - val_loss: 0.4470 - val_mae: 0.4072 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4299 - mae: 0.4219\n",
      "Epoch 87: val_loss did not improve from 0.44585\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.4299 - mae: 0.4219 - val_loss: 0.4517 - val_mae: 0.4081 - learning_rate: 0.0010\n",
      "Epoch 88/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4217 - mae: 0.4208\n",
      "Epoch 88: val_loss improved from 0.44585 to 0.44306, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 0.4217 - mae: 0.4208 - val_loss: 0.4431 - val_mae: 0.4025 - learning_rate: 0.0010\n",
      "Epoch 89/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4174 - mae: 0.4186\n",
      "Epoch 89: val_loss improved from 0.44306 to 0.44171, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.4174 - mae: 0.4186 - val_loss: 0.4417 - val_mae: 0.4036 - learning_rate: 0.0010\n",
      "Epoch 90/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.4113 - mae: 0.4172\n",
      "Epoch 90: val_loss did not improve from 0.44171\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 0.4113 - mae: 0.4172 - val_loss: 0.4496 - val_mae: 0.4001 - learning_rate: 0.0010\n",
      "Epoch 91/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4243 - mae: 0.4187\n",
      "Epoch 91: val_loss improved from 0.44171 to 0.43681, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.4242 - mae: 0.4187 - val_loss: 0.4368 - val_mae: 0.3992 - learning_rate: 0.0010\n",
      "Epoch 92/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4211 - mae: 0.4153\n",
      "Epoch 92: val_loss did not improve from 0.43681\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - loss: 0.4211 - mae: 0.4153 - val_loss: 0.4642 - val_mae: 0.4072 - learning_rate: 0.0010\n",
      "Epoch 93/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.4256 - mae: 0.4186\n",
      "Epoch 93: val_loss improved from 0.43681 to 0.43537, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 0.4255 - mae: 0.4186 - val_loss: 0.4354 - val_mae: 0.3997 - learning_rate: 0.0010\n",
      "Epoch 94/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.4162 - mae: 0.4158\n",
      "Epoch 94: val_loss did not improve from 0.43537\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.4162 - mae: 0.4158 - val_loss: 0.4662 - val_mae: 0.4076 - learning_rate: 0.0010\n",
      "Epoch 95/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4145 - mae: 0.4163\n",
      "Epoch 95: val_loss did not improve from 0.43537\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.4145 - mae: 0.4163 - val_loss: 0.4622 - val_mae: 0.4057 - learning_rate: 0.0010\n",
      "Epoch 96/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4142 - mae: 0.4142\n",
      "Epoch 96: val_loss did not improve from 0.43537\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 0.4142 - mae: 0.4142 - val_loss: 0.4412 - val_mae: 0.3959 - learning_rate: 0.0010\n",
      "Epoch 97/100\n",
      "\u001b[1m207/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4123 - mae: 0.4133\n",
      "Epoch 97: val_loss did not improve from 0.43537\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 0.4123 - mae: 0.4133 - val_loss: 0.4449 - val_mae: 0.3964 - learning_rate: 0.0010\n",
      "Epoch 98/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4151 - mae: 0.4140\n",
      "Epoch 98: val_loss improved from 0.43537 to 0.43174, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.4150 - mae: 0.4140 - val_loss: 0.4317 - val_mae: 0.3988 - learning_rate: 0.0010\n",
      "Epoch 99/100\n",
      "\u001b[1m208/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4149 - mae: 0.4128\n",
      "Epoch 99: val_loss improved from 0.43174 to 0.42717, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 0.4149 - mae: 0.4128 - val_loss: 0.4272 - val_mae: 0.3958 - learning_rate: 0.0010\n",
      "Epoch 100/100\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4160 - mae: 0.4125\n",
      "Epoch 100: val_loss did not improve from 0.42717\n",
      "\u001b[1m209/209\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 0.4160 - mae: 0.4125 - val_loss: 0.4284 - val_mae: 0.3933 - learning_rate: 0.0010\n",
      "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "MAE: 0.3934669632417792\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_lstm\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_absolute_error(Y_test, y_pred))\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR² Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, r2_score(Y_test, y_pred))\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:194\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m params \u001b[38;5;241m=\u001b[39m func_sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    195\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3183\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3184\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\indian_agriculture\\myenv\\lib\\inspect.py:3175\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3173\u001b[0m         arguments[kwargs_param\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m   3174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3176\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   3177\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[0;32m   3179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[1;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "def build_lstm_model(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = LSTM(128, return_sequences=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    outputs = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "input_shape = (x_train_scaled.shape[1], x_train_scaled.shape[2])\n",
    "\n",
    "model_lstm = build_lstm_model(input_shape)\n",
    "\n",
    "# 5. Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "# 6. Train the Model\n",
    "history = model_lstm.fit(\n",
    "    x_train_scaled, y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 7. Evaluate the Model\n",
    "y_pred = model_lstm.predict(X_test).flatten()\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(Y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(Y_test, y_pred, squared=False))\n",
    "print(\"R² Score:\", r2_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cf9e5bc9-69b3-4c7d-b6bd-ce8b0e06d385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.3934669632417792\n",
      "RMSE: 0.41342537348758407\n",
      "R² Score: 0.7212103886719503\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE:\", mean_absolute_error(Y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(Y_test, y_pred))\n",
    "print(\"R² Score:\", r2_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "89fdfe51-7d1f-4f97-8775-28b99011ea5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8483749253343601, 0.9905486457436928)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_RFR = RandomForestRegressor()\n",
    "model_RFR.fit(x_train_for_scaling,y_train)\n",
    "y_test_RFR_predict = model_RFR.predict(x_test_for_scaling)\n",
    "y_train_RFR_predict = model_RFR.predict(x_train_for_scaling)\n",
    "r2_score(y_test,y_test_RFR_predict) , r2_score(y_train, y_train_RFR_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce14b267-1be8-4473-ae1b-22a5278c6cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8483749253343601, 0.9905486457436928)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_test_RFR_predict) , r2_score(y_train, y_train_RFR_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55edfbec-0b07-4d6d-85c7-2247ca210e37",
   "metadata": {},
   "source": [
    "Hyperparmeter tunning with catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b264821c-1b88-4609-b3a1-4c070ade92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install catboost optuna --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fde3a423-7bf5-44b8-9003-9162d03b88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e175965a-a450-4a0a-a0b2-21ef63f94a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a17e8c55-666f-4a3d-bcd8-20002088ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to search\n",
    "    bootstrap_type = trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\"])\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 500, 2000),\n",
    "        'depth': trial.suggest_int('depth', 4, 8),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 3, 30, log=True),\n",
    "        \n",
    "        'random_strength': trial.suggest_float('random_strength', 1e-9, 10, log=True),\n",
    "        'border_count': trial.suggest_int('border_count', 64, 254),\n",
    "        'bootstrap_type': bootstrap_type,\n",
    "        \n",
    "\n",
    "        \n",
    "        # Fixed GPU params\n",
    "        'task_type': 'GPU',\n",
    "        'devices': '0',\n",
    "        'eval_metric': 'R2',\n",
    "        'loss_function': 'RMSE',\n",
    "        'early_stopping_rounds': 50,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    if bootstrap_type == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 1)\n",
    "    else:  # Bernoulli\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.5, 0.9)\n",
    "\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "\n",
    "    train_pool = Pool(x_train, y_train, cat_features=['season', 'crop'])\n",
    "    test_pool = Pool(x_test, y_test, cat_features=['season', 'crop'])\n",
    "\n",
    "    model.fit(train_pool, eval_set=test_pool)\n",
    "    preds = model.predict(x_test)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    \n",
    "    return r2  # maximize R² score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bd72ab6c-01f0-4b8f-9550-826ef63d5a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-31 22:43:39,316] A new study created in memory with name: no-name-1028abf8-fdad-4c06-bf5e-4ba6fdeb38cd\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:44:34,609] Trial 0 finished with value: 0.8050860903288083 and parameters: {'bootstrap_type': 'Bernoulli', 'iterations': 1193, 'depth': 4, 'learning_rate': 0.021172503334295583, 'l2_leaf_reg': 18.618991728273702, 'random_strength': 1.2264502488487885e-09, 'border_count': 209, 'subsample': 0.5104275697481206}. Best is trial 0 with value: 0.8050860903288083.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:45:13,428] Trial 1 finished with value: 0.7787767567080331 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 925, 'depth': 4, 'learning_rate': 0.013024264537052365, 'l2_leaf_reg': 10.806963567006393, 'random_strength': 2.7343748067428474e-06, 'border_count': 138, 'bagging_temperature': 0.6884907672129524}. Best is trial 0 with value: 0.8050860903288083.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:45:54,217] Trial 2 finished with value: 0.8338727750371205 and parameters: {'bootstrap_type': 'Bernoulli', 'iterations': 1957, 'depth': 6, 'learning_rate': 0.07625246461745842, 'l2_leaf_reg': 3.1901334338772176, 'random_strength': 6.287301970848111e-08, 'border_count': 81, 'subsample': 0.7674085689155923}. Best is trial 2 with value: 0.8338727750371205.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:46:33,931] Trial 3 finished with value: 0.8396234689588188 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1236, 'depth': 8, 'learning_rate': 0.07503728475238682, 'l2_leaf_reg': 23.00993630222385, 'random_strength': 4.28013003256645, 'border_count': 172, 'bagging_temperature': 0.6913154335511176}. Best is trial 3 with value: 0.8396234689588188.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:47:40,331] Trial 4 finished with value: 0.8030818568702058 and parameters: {'bootstrap_type': 'Bernoulli', 'iterations': 1951, 'depth': 4, 'learning_rate': 0.011158482344980274, 'l2_leaf_reg': 7.0969390193677295, 'random_strength': 0.07556133137521288, 'border_count': 228, 'subsample': 0.7047380083192583}. Best is trial 3 with value: 0.8396234689588188.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:48:23,130] Trial 5 finished with value: 0.833281006288101 and parameters: {'bootstrap_type': 'Bernoulli', 'iterations': 786, 'depth': 6, 'learning_rate': 0.059617161610711566, 'l2_leaf_reg': 7.942851660189005, 'random_strength': 2.5108116146321675e-09, 'border_count': 125, 'subsample': 0.5339350153413354}. Best is trial 3 with value: 0.8396234689588188.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:49:20,617] Trial 6 finished with value: 0.8300739223882505 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1794, 'depth': 5, 'learning_rate': 0.07620170454559745, 'l2_leaf_reg': 5.53054097130574, 'random_strength': 0.011438264905306514, 'border_count': 167, 'bagging_temperature': 0.21261921933066819}. Best is trial 3 with value: 0.8396234689588188.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:50:17,444] Trial 7 finished with value: 0.8306151861350826 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 634, 'depth': 8, 'learning_rate': 0.023800465324596252, 'l2_leaf_reg': 6.775804037569271, 'random_strength': 1.4477307850434982e-08, 'border_count': 87, 'bagging_temperature': 0.9357989435437988}. Best is trial 3 with value: 0.8396234689588188.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:51:04,599] Trial 8 finished with value: 0.813305916518523 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1259, 'depth': 4, 'learning_rate': 0.03134440601254027, 'l2_leaf_reg': 5.164678805776071, 'random_strength': 2.7436318055583616e-08, 'border_count': 197, 'bagging_temperature': 0.6250676931432563}. Best is trial 3 with value: 0.8396234689588188.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:51:44,116] Trial 9 finished with value: 0.8240004141504831 and parameters: {'bootstrap_type': 'Bernoulli', 'iterations': 1070, 'depth': 5, 'learning_rate': 0.02944751731107954, 'l2_leaf_reg': 7.074070891676973, 'random_strength': 2.505230859067043e-07, 'border_count': 78, 'subsample': 0.5304153823703319}. Best is trial 3 with value: 0.8396234689588188.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:53:29,087] Trial 10 finished with value: 0.8425539713538439 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1493, 'depth': 8, 'learning_rate': 0.0497929572285106, 'l2_leaf_reg': 29.311173580453964, 'random_strength': 2.8008818821700596, 'border_count': 243, 'bagging_temperature': 0.26461899880099465}. Best is trial 10 with value: 0.8425539713538439.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:55:50,797] Trial 11 finished with value: 0.843252713719096 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1494, 'depth': 8, 'learning_rate': 0.047669359625121234, 'l2_leaf_reg': 28.912662605733168, 'random_strength': 9.202486243864476, 'border_count': 244, 'bagging_temperature': 0.16986234038101233}. Best is trial 11 with value: 0.843252713719096.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:57:35,925] Trial 12 finished with value: 0.8405353147791115 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1523, 'depth': 7, 'learning_rate': 0.04964548169458341, 'l2_leaf_reg': 29.19338580533307, 'random_strength': 5.330259312588436, 'border_count': 252, 'bagging_temperature': 0.11537690219060481}. Best is trial 11 with value: 0.843252713719096.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 22:59:14,380] Trial 13 finished with value: 0.8403140433592238 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1507, 'depth': 7, 'learning_rate': 0.04436619265039486, 'l2_leaf_reg': 13.361500036061983, 'random_strength': 0.009384194835389102, 'border_count': 251, 'bagging_temperature': 0.30879707487432506}. Best is trial 11 with value: 0.843252713719096.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:01:06,677] Trial 14 finished with value: 0.8428820492054665 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1525, 'depth': 8, 'learning_rate': 0.04224135944476867, 'l2_leaf_reg': 29.202150918952224, 'random_strength': 6.440042634336534e-05, 'border_count': 221, 'bagging_temperature': 0.007507597718735437}. Best is trial 11 with value: 0.843252713719096.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:02:56,343] Trial 15 finished with value: 0.8408379800817921 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1713, 'depth': 7, 'learning_rate': 0.03723529532406362, 'l2_leaf_reg': 16.13102544049512, 'random_strength': 0.00017626539341836442, 'border_count': 203, 'bagging_temperature': 0.03262793904650693}. Best is trial 11 with value: 0.843252713719096.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:04:31,289] Trial 16 finished with value: 0.8454663611932107 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1415, 'depth': 8, 'learning_rate': 0.09631690416150157, 'l2_leaf_reg': 20.48747200558469, 'random_strength': 8.93025501491342e-05, 'border_count': 221, 'bagging_temperature': 0.003419592111004288}. Best is trial 16 with value: 0.8454663611932107.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:05:37,988] Trial 17 finished with value: 0.8408534004153237 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1338, 'depth': 7, 'learning_rate': 0.09446674046056547, 'l2_leaf_reg': 20.73268062581156, 'random_strength': 7.91673594425527e-05, 'border_count': 193, 'bagging_temperature': 0.43761039218789266}. Best is trial 16 with value: 0.8454663611932107.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:08:04,399] Trial 18 finished with value: 0.8396949813105391 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1666, 'depth': 8, 'learning_rate': 0.017292343916777267, 'l2_leaf_reg': 13.861027167253205, 'random_strength': 4.6654041866783e-06, 'border_count': 228, 'bagging_temperature': 0.4240342913946392}. Best is trial 16 with value: 0.8454663611932107.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:08:51,800] Trial 19 finished with value: 0.8400073693379181 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1032, 'depth': 7, 'learning_rate': 0.09980568298525473, 'l2_leaf_reg': 23.282768926951636, 'random_strength': 0.0017864078799330364, 'border_count': 181, 'bagging_temperature': 0.15382700853227738}. Best is trial 16 with value: 0.8454663611932107.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:09:28,236] Trial 20 finished with value: 0.828803265172152 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 512, 'depth': 6, 'learning_rate': 0.06144987109705643, 'l2_leaf_reg': 10.335359416010718, 'random_strength': 0.5542789785485845, 'border_count': 145, 'bagging_temperature': 0.3400876138301183}. Best is trial 16 with value: 0.8454663611932107.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:11:19,716] Trial 21 finished with value: 0.843168031118747 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1423, 'depth': 8, 'learning_rate': 0.04085293665110681, 'l2_leaf_reg': 29.637795809586223, 'random_strength': 0.00018146478685553418, 'border_count': 225, 'bagging_temperature': 0.030906948295538497}. Best is trial 16 with value: 0.8454663611932107.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:12:48,454] Trial 22 finished with value: 0.8426328481436803 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1369, 'depth': 8, 'learning_rate': 0.03562980598879758, 'l2_leaf_reg': 23.731760929701906, 'random_strength': 5.313617808998078e-06, 'border_count': 235, 'bagging_temperature': 0.0887856818361472}. Best is trial 16 with value: 0.8454663611932107.\n",
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "[I 2025-05-31 23:14:49,583] Trial 23 finished with value: 0.8457275130846733 and parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1622, 'depth': 8, 'learning_rate': 0.06141812877834573, 'l2_leaf_reg': 18.611897930225016, 'random_strength': 0.0008427828569398906, 'border_count': 214, 'bagging_temperature': 0.023323595597567325}. Best is trial 23 with value: 0.8457275130846733.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, timeout=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8ff407ab-4856-4747-82b8-3240c7f7696e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial Score: 0.8457275130846733\n",
      "Best Parameters: {'bootstrap_type': 'Bayesian', 'iterations': 1622, 'depth': 8, 'learning_rate': 0.06141812877834573, 'l2_leaf_reg': 18.611897930225016, 'random_strength': 0.0008427828569398906, 'border_count': 214, 'bagging_temperature': 0.023323595597567325}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Trial Score:\", study.best_value)\n",
    "print(\"Best Parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a968cb19-81ed-406b-aebd-374237e451c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because R2 is/are not implemented for GPU\n",
      "Metric R2 is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0707818\ttest: 0.0708059\tbest: 0.0708059 (0)\ttotal: 83.1ms\tremaining: 2m 14s\n",
      "100:\tlearn: 0.8333684\ttest: 0.8054403\tbest: 0.8054403 (100)\ttotal: 6.43s\tremaining: 1m 36s\n",
      "200:\tlearn: 0.8686105\ttest: 0.8241859\tbest: 0.8241859 (200)\ttotal: 13.5s\tremaining: 1m 35s\n",
      "300:\tlearn: 0.8852549\ttest: 0.8331705\tbest: 0.8331887 (294)\ttotal: 20.3s\tremaining: 1m 29s\n",
      "400:\tlearn: 0.8936123\ttest: 0.8366404\tbest: 0.8366404 (400)\ttotal: 26.4s\tremaining: 1m 20s\n",
      "500:\tlearn: 0.9003385\ttest: 0.8398225\tbest: 0.8398225 (500)\ttotal: 33.2s\tremaining: 1m 14s\n",
      "600:\tlearn: 0.9061282\ttest: 0.8420669\tbest: 0.8420669 (600)\ttotal: 39.8s\tremaining: 1m 7s\n",
      "700:\tlearn: 0.9102081\ttest: 0.8429378\tbest: 0.8429915 (699)\ttotal: 46.5s\tremaining: 1m 1s\n",
      "800:\tlearn: 0.9134595\ttest: 0.8439791\tbest: 0.8440103 (797)\ttotal: 53s\tremaining: 54.3s\n",
      "900:\tlearn: 0.9163000\ttest: 0.8448276\tbest: 0.8448427 (899)\ttotal: 1m\tremaining: 48.1s\n",
      "1000:\tlearn: 0.9184640\ttest: 0.8456158\tbest: 0.8456174 (994)\ttotal: 1m 7s\tremaining: 41.8s\n",
      "1100:\tlearn: 0.9204027\ttest: 0.8462222\tbest: 0.8462222 (1100)\ttotal: 1m 14s\tremaining: 35.2s\n",
      "1200:\tlearn: 0.9223582\ttest: 0.8463790\tbest: 0.8464562 (1179)\ttotal: 1m 21s\tremaining: 28.7s\n",
      "1300:\tlearn: 0.9241740\ttest: 0.8465605\tbest: 0.8466672 (1291)\ttotal: 1m 28s\tremaining: 22s\n",
      "bestTest = 0.8466672163\n",
      "bestIteration = 1291\n",
      "Shrink model to first 1292 iterations.\n",
      "Final R2: 0.8466672103473695\n",
      "MAE: 0.23824503094719784\n",
      "RMSE: 0.22437794522297763\n"
     ]
    }
   ],
   "source": [
    "best_model = CatBoostRegressor(**study.best_params,\n",
    "                                task_type='GPU',\n",
    "                                devices='0',\n",
    "                                eval_metric='R2',\n",
    "                                loss_function='RMSE',\n",
    "                                early_stopping_rounds=50,\n",
    "                                verbose=100)\n",
    "\n",
    "train_pool = Pool(x_train, y_train, cat_features=['season', 'crop'])\n",
    "test_pool = Pool(x_test, y_test, cat_features=['season', 'crop'])\n",
    "\n",
    "best_model.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "# Final prediction & evaluation\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(\"Final R2:\", r2_score(y_test, y_pred))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3e2931ff-83ef-4d31-859f-502336fdc209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9261057404325903"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = best_model.predict(x_train)\n",
    "r2_score(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c6660ac7-ef8d-4517-8cf2-dd11d25f3d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8466672103473695"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "489812c6-7c73-419b-8573-7ad6b8bbbd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"catboost_best_model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "51256a93-dd02-4533-ac1e-e047fd2bded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "363bf5a3-61e4-4fee-9f51-9ef223e2e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CatBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e44db387-d002-4c4c-b5f1-96974c7282c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x2c480466050>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_model('catboost_best_model.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "510f3d18-fcff-4107-b8b0-0895d3787f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_year</th>\n",
       "      <th>season</th>\n",
       "      <th>crop</th>\n",
       "      <th>area</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>relative_humidity_2m_mean</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196293</th>\n",
       "      <td>2018</td>\n",
       "      <td>kharif</td>\n",
       "      <td>arhar/tur</td>\n",
       "      <td>8.337827</td>\n",
       "      <td>30.524337</td>\n",
       "      <td>1.639104</td>\n",
       "      <td>57.123297</td>\n",
       "      <td>18.537061</td>\n",
       "      <td>14.475294</td>\n",
       "      <td>78.821686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196292</th>\n",
       "      <td>2018</td>\n",
       "      <td>rabi</td>\n",
       "      <td>arhar/tur</td>\n",
       "      <td>6.966967</td>\n",
       "      <td>27.324539</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>65.982719</td>\n",
       "      <td>9.026267</td>\n",
       "      <td>16.291519</td>\n",
       "      <td>80.454159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196323</th>\n",
       "      <td>2018</td>\n",
       "      <td>kharif</td>\n",
       "      <td>bajra</td>\n",
       "      <td>4.418841</td>\n",
       "      <td>28.712652</td>\n",
       "      <td>8.850824</td>\n",
       "      <td>77.973477</td>\n",
       "      <td>9.236416</td>\n",
       "      <td>18.114126</td>\n",
       "      <td>83.411439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196322</th>\n",
       "      <td>2018</td>\n",
       "      <td>kharif</td>\n",
       "      <td>bajra</td>\n",
       "      <td>4.442651</td>\n",
       "      <td>28.544194</td>\n",
       "      <td>9.827921</td>\n",
       "      <td>81.937993</td>\n",
       "      <td>11.404050</td>\n",
       "      <td>18.294931</td>\n",
       "      <td>83.893884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196321</th>\n",
       "      <td>2018</td>\n",
       "      <td>rabi</td>\n",
       "      <td>bajra</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>26.882892</td>\n",
       "      <td>0.226152</td>\n",
       "      <td>66.549539</td>\n",
       "      <td>9.343433</td>\n",
       "      <td>14.717439</td>\n",
       "      <td>79.660506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249491</th>\n",
       "      <td>2020</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>9.114160</td>\n",
       "      <td>12.551224</td>\n",
       "      <td>2.734038</td>\n",
       "      <td>60.397664</td>\n",
       "      <td>3.186096</td>\n",
       "      <td>30.729860</td>\n",
       "      <td>78.443420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249460</th>\n",
       "      <td>2020</td>\n",
       "      <td>wholeyear</td>\n",
       "      <td>turmeric</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>12.463553</td>\n",
       "      <td>6.557644</td>\n",
       "      <td>56.127426</td>\n",
       "      <td>3.479982</td>\n",
       "      <td>30.608720</td>\n",
       "      <td>79.065170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249485</th>\n",
       "      <td>2020</td>\n",
       "      <td>rabi</td>\n",
       "      <td>wheat</td>\n",
       "      <td>9.965476</td>\n",
       "      <td>7.998832</td>\n",
       "      <td>2.927197</td>\n",
       "      <td>71.856507</td>\n",
       "      <td>5.530812</td>\n",
       "      <td>29.390529</td>\n",
       "      <td>79.460869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249431</th>\n",
       "      <td>2020</td>\n",
       "      <td>kharif</td>\n",
       "      <td>soyabean</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>19.961075</td>\n",
       "      <td>13.932401</td>\n",
       "      <td>85.659140</td>\n",
       "      <td>3.244839</td>\n",
       "      <td>30.008790</td>\n",
       "      <td>79.928018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249468</th>\n",
       "      <td>2020</td>\n",
       "      <td>summer</td>\n",
       "      <td>urad</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>23.703710</td>\n",
       "      <td>1.304355</td>\n",
       "      <td>55.102151</td>\n",
       "      <td>5.963441</td>\n",
       "      <td>30.325565</td>\n",
       "      <td>78.043681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35974 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crop_year     season       crop      area  ...  relative_humidity_2m_mean  wind_speed_10m_mean   latitude  longitude\n",
       "196293       2018     kharif  arhar/tur  8.337827  ...                  57.123297            18.537061  14.475294  78.821686\n",
       "196292       2018       rabi  arhar/tur  6.966967  ...                  65.982719             9.026267  16.291519  80.454159\n",
       "196323       2018     kharif      bajra  4.418841  ...                  77.973477             9.236416  18.114126  83.411439\n",
       "196322       2018     kharif      bajra  4.442651  ...                  81.937993            11.404050  18.294931  83.893884\n",
       "196321       2018       rabi      bajra  0.693147  ...                  66.549539             9.343433  14.717439  79.660506\n",
       "...           ...        ...        ...       ...  ...                        ...                  ...        ...        ...\n",
       "249491       2020       rabi      wheat  9.114160  ...                  60.397664             3.186096  30.729860  78.443420\n",
       "249460       2020  wholeyear   turmeric  0.693147  ...                  56.127426             3.479982  30.608720  79.065170\n",
       "249485       2020       rabi      wheat  9.965476  ...                  71.856507             5.530812  29.390529  79.460869\n",
       "249431       2020     kharif   soyabean  3.610918  ...                  85.659140             3.244839  30.008790  79.928018\n",
       "249468       2020     summer       urad  2.302585  ...                  55.102151             5.963441  30.325565  78.043681\n",
       "\n",
       "[35974 rows x 10 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1106037a-5a17-4ae3-9057-9506195222bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.DataFrame([{\n",
    "                    \"crop_year\": 2021,\n",
    "                    \"season\": 'Kharif',\n",
    "                    \"crop\": 'bajra',\n",
    "                    \"area\": np.log1p(50000),\n",
    "                    \"temperature_2m_mean\": 25,\n",
    "                    \"precipitation_sum\": 66,\n",
    "                    \"relative_humidity_2m_mean\": 30,\n",
    "                    \"wind_speed_10m_mean\": 10,\n",
    "                    \"latitude\": 14,\n",
    "                    \"longitude\": 78,\n",
    "                }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "034df428-52d1-4140-8c09-5406c45e5e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8726691])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da42612a-47b5-4b84-9aed-cdc7273c9d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
